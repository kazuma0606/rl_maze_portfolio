# 要件定義書

## はじめに

RL Maze Phase 1は、強化学習エージェントが迷路を自律探索する様子をリアルタイムで可視化するポートフォリオプロジェクトの基盤フェーズである。本フェーズでは、実験検証（Jupyter Notebook）、迷路環境実装、RLモデル訓練（PPO/DQN）、ONNX変換、Go推論サーバー、NextJS推論UIまでのエンドツーエンドフローを確立する。

本システムは「AI実験を本番運用可能なシステムへ接続する最小構成」を示すことを目的とし、クリーンアーキテクチャ・型安全性・観測可能性・将来のクラウド移行を前提とした設計判断を含む。

## 用語集

- **システム**: RL Maze Phase 1システム全体（実験環境・訓練サービス・推論サーバー・フロントエンドUIを含む）
- **迷路環境**: OpenAI Gym互換の迷路環境（10×10グリッド、部分観測5×5）
- **訓練サービス**: Python + Stable-Baselines3によるRL訓練パイプライン
- **推論サーバー**: Go + Ginによる推論APIサーバー（ONNX推論・WebSocket・REST API）
- **フロントエンドUI**: Next.js + TypeScriptによる推論可視化UI（Canvas描画・WebSocket受信）
- **ONNXモデル**: 訓練済みRLモデルをONNX形式に変換したファイル
- **MLflow**: 実験トラッキング・メトリクス記録システム
- **エージェント**: 迷路内を探索する強化学習エージェント
- **エピソード**: エージェントがスタートからゴール到達または最大ステップ超過までの1試行
- **Q値**: 状態-行動価値関数の値（DQNで使用）
- **Port**: ドメイン層が定義するインターフェース（クリーンアーキテクチャ）
- **Adapter**: Portを実装するインフラ層の具象クラス

## 要件

### 要件1

**ユーザーストーリー:** 開発者として、本実装前にJupyter NotebookでRLアルゴリズムとONNX変換を検証したい。そうすることで技術リスクを早期に特定し、実現可能性を確認できる。

#### 受け入れ条件

1. 開発者が `00_rl_basic.ipynb` を実行したとき、システムはCartPole環境でランダムエージェントと訓練済みエージェントのアニメーションを並べて表示しなければならない
2. 開発者が `01_dqn_basic.ipynb` を実行したとき、システムはCartPoleでDQNエージェントを訓練し、エピソード報酬の学習曲線を記録しなければならない
3. 開発者が `02_ppo_basic.ipynb` を実行したとき、システムはCartPoleでPPOエージェントを訓練し、エピソード報酬の学習曲線を記録しなければならない
4. 開発者が `03_maze_env.ipynb` を実行したとき、システムは迷路環境を実装し、報酬設計の検証を行わなければならない
5. 開発者が `04_onnx_export.ipynb` を実行したとき、システムはStable-Baselines3モデルをONNX形式に変換し、入出力シェイプを検証しなければならない
6. 開発者が `go_onnx_validation/main.go` を実行したとき、システムはONNXモデルをロードして推論を実行し、Go-ONNX統合を検証しなければならない

### 要件2

**ユーザーストーリー:** 開発者として、部分観測を持つGym互換の迷路環境が欲しい。そうすることで現実的な制約の下でRLエージェントを訓練できる。

#### 受け入れ条件

1. 迷路環境が初期化されたとき、システムは壁・通路・スタート位置・ゴール位置を持つ10×10グリッドを作成しなければならない
2. エージェントが `reset()` を呼び出したとき、迷路環境はエージェント周囲5×5の部分観測を表す25次元の観測ベクトルを返さなければならない
3. エージェントが有効な行動（0=上、1=下、2=左、3=右）で `step(action)` を呼び出したとき、迷路環境は観測・報酬・終了フラグ・情報辞書を返さなければならない
4. エージェントがゴール位置に到達したとき、迷路環境は報酬+1.0とdone=Trueを返さなければならない
5. エージェントがゴールに到達せずにステップを踏んだとき、迷路環境は報酬-0.01を返さなければならない
6. エージェントが壁に移動しようとしたとき、迷路環境は報酬-0.05を返し、エージェントを現在位置に留めなければならない
7. エージェントが200ステップを超えたとき、迷路環境はdone=Trueを返さなければならない
8. 迷路環境に行動空間を問い合わせたとき、システムはDiscrete(4)を返さなければならない
9. 迷路環境に観測空間を問い合わせたとき、システムはBox(shape=(25,))を返さなければならない

### 要件3

**ユーザーストーリー:** 開発者として、PPOまたはDQNアルゴリズムを使ってRLエージェントを訓練したい。そうすることでパフォーマンスを比較し、最適なアプローチを選択できる。

#### 受け入れ条件

1. 訓練サービスがalgorithm="PPO"の訓練リクエストを受け取ったとき、システムはStable-Baselines3を使ってPPOエージェントを初期化しなければならない
2. 訓練サービスがalgorithm="DQN"の訓練リクエストを受け取ったとき、システムはStable-Baselines3を使ってDQNエージェントを初期化しなければならない
3. 訓練サービスが訓練を開始したとき、システムは毎エピソードのエピソード報酬をMLflowに記録しなければならない
4. 訓練サービスが訓練を開始したとき、システムは毎エピソードのエピソード長をMLflowに記録しなければならない
5. 訓練サービスが訓練を開始したとき、システムは毎エピソードの損失値をMLflowに記録しなければならない
6. 訓練サービスが訓練を開始したとき、システムは10エピソードごとに成功率（ゴール到達数/総エピソード数）をMLflowに記録しなければならない
7. 訓練が完了したとき、訓練サービスは迷路環境で成功率70%以上を達成しなければならない
8. 訓練が完了したとき、訓練サービスは訓練済みモデルを自動的にONNX形式に変換しなければならない
9. 訓練が完了したとき、訓練サービスはONNXモデルを `ml/models/` ディレクトリに保存しなければならない
10. 訓練が完了したとき、訓練サービスはモデルメタデータ（アルゴリズム・訓練日時・成功率・ONNXファイルパス）をPostgreSQLに登録しなければならない
11. 訓練サービスが `POST /training/start` へのRESTリクエストを受け取ったとき、システムは訓練を開始し、一意のexperiment_idを返さなければならない
12. 訓練サービスが `GET /training/status/{experiment_id}` へのRESTリクエストを受け取ったとき、システムは訓練ステータスを返さなければならない
13. 訓練サービスが `POST /training/stop/{experiment_id}` へのRESTリクエストを受け取ったとき、システムは訓練を停止しなければならない
14. 訓練サービスが `/ws/training/{experiment_id}` へのWebSocket接続を受け取ったとき、システムは接続を確立し、訓練進捗を10秒ごとにストリーミングしなければならない
15. 訓練サービスが `GET /experiments` へのRESTリクエストを受け取ったとき、システムはMLflowから実験一覧を取得して返さなければならない
16. 訓練サービスが `GET /experiments/{experiment_id}` へのRESTリクエストを受け取ったとき、システムはMLflowから実験詳細（メトリクス履歴含む）を取得して返さなければならない

### 要件4

**ユーザーストーリー:** 開発者として、クリーンアーキテクチャを持つGo推論サーバーが欲しい。そうすることで低レイテンシ推論と将来のAWS移行能力を確保できる。

#### 受け入れ条件

1. 推論サーバーが起動したとき、システムはアクティブなONNXモデルをメモリにロードしなければならない
2. 推論サーバーが観測ベクトルを受け取ったとき、システムはONNXランタイムを使って推論を実行し、50ms以内（p95）に行動とQ値を返さなければならない
3. 推論サーバーが `GET /health` へのRESTリクエストを受け取ったとき、システムはHTTP 200とステータス"healthy"を返さなければならない
4. 推論サーバーが `GET /api/models` へのRESTリクエストを受け取ったとき、システムはPostgreSQLから利用可能なモデルのリストを返さなければならない
5. 推論サーバーがmodel_idを含む `POST /api/models/active` へのRESTリクエストを受け取ったとき、システムはPostgreSQLのアクティブモデル参照を更新しなければならない
6. 推論サーバーが `/ws/inference` へのWebSocket接続を受け取ったとき、システムは接続を確立し、推論結果をストリーミングしなければならない
7. 推論サーバーが推論を実行したとき、システムはrequest_id・duration_ms・model_idをJSON形式でMongoDBにログ記録しなければならない
8. 推論サーバーがエラーに遭遇したとき、システムはエラー詳細をJSON形式でMongoDBにログ記録しなければならない
9. ドメイン層のコードがコンパイルされたとき、システムは外部依存（データベース・ONNX・HTTPフレームワーク）をインポートしてはならない
10. ユースケース層のコードがコンパイルされたとき、システムはドメイン層のPortのみに依存しなければならない
11. インフラ層のコードがコンパイルされたとき、システムはドメイン層のPortを実装しなければならない

### 要件5

**ユーザーストーリー:** ユーザーとして、エージェントの振る舞いをリアルタイムで可視化するUIが欲しい。そうすることでエージェントの意思決定プロセスを観察し理解できる。

#### 受け入れ条件

1. フロントエンドUIがロードされたとき、システムはCanvas APIを使って10×10の迷路グリッドを表示しなければならない
2. フロントエンドUIが推論サーバーへのWebSocket接続を確立したとき、システムは接続ステータスを緑色で"Connected"と表示しなければならない
3. WebSocket接続が失われたとき、フロントエンドUIはステータスを赤色で"Disconnected"と表示し、自動再接続を試みなければならない
4. フロントエンドUIがWebSocket経由で推論データを受信したとき、システムは200ms以内にCanvas上のエージェント位置を更新しなければならない
5. フロントエンドUIが推論データを受信したとき、システムは各セルにQ値方向矢印を表示しなければならない
6. フロントエンドUIが推論データを受信したとき、システムは訪問済みセルを色分けしてハイライト表示しなければならない
7. ユーザーが"Play"ボタンをクリックしたとき、フロントエンドUIはWebSocket経由で推論リクエストのストリーミングを開始しなければならない
8. ユーザーが"Stop"ボタンをクリックしたとき、フロントエンドUIは推論ストリーミングを一時停止しなければならない
9. ユーザーが"Reset"ボタンをクリックしたとき、フロントエンドUIは迷路とエージェントを初期状態にリセットしなければならない
10. ユーザーが速度スライダーを調整したとき、フロントエンドUIは推論リクエスト頻度をそれに応じて変更しなければならない
11. フロントエンドUIがメトリクスタブを表示したとき、システムは現在のステップ数・報酬・行動・最大Q値を表示しなければならない
12. フロントエンドUIが累積報酬グラフを表示したとき、システムはエージェントの進行に合わせてグラフをリアルタイムで更新しなければならない

### 要件6

**ユーザーストーリー:** 開発者として、構造化ログと実験トラッキングが欲しい。そうすることでシステムの振る舞いを監視し、訓練実行を比較できる。

#### 受け入れ条件

1. 推論サーバーがリクエストを処理したとき、システムはtimestamp・level・request_id・duration_msを含む構造化JSONログを出力しなければならない
2. 推論サーバーがエラーに遭遇したとき、システムはtimestamp・level・エラーメッセージ・スタックトレースを含む構造化JSONログを出力しなければならない
3. 訓練サービスが実験を開始したとき、システムは一意のexperiment_idを持つ新しいMLflow実験を作成しなければならない
4. 訓練サービスがメトリクスを記録したとき、システムはエピソード報酬・エピソード長・損失・成功率をMLflowに送信しなければならない
5. 訓練サービスが訓練を完了したとき、システムは最終モデルをメタデータと共にMLflowに登録しなければならない
6. MLflowがメトリクスを受信したとき、システムはデータをPostgreSQLバックエンドストレージに永続化しなければならない

### 要件7

**ユーザーストーリー:** 開発者として、環境ベースの設定管理が欲しい。そうすることでコード変更なしにローカル環境と本番環境を切り替えられる。

#### 受け入れ条件

1. 推論サーバーが起動したとき、システムは環境変数からDATABASE_URLを読み込まなければならない
2. 推論サーバーが起動したとき、システムは環境変数からMONGODB_URIを読み込まなければならない
3. 訓練サービスが起動したとき、システムは環境変数からMLFLOW_TRACKING_URIを読み込まなければならない
4. フロントエンドUIがビルドされたとき、システムは環境変数からNEXT_PUBLIC_WS_URLを読み込まなければならない
5. 開発者が `docker-compose up` を実行したとき、システムはローカル環境変数でPostgreSQL・MongoDB・全サービスを起動しなければならない
6. 環境変数が欠落しているとき、システムはどの変数が必要かを示す明確なエラーメッセージと共に即座に失敗しなければならない

### 要件8

**ユーザーストーリー:** 開発者として、明確なサービス境界を持つモノレポ構造が欲しい。そうすることで複数のサービスを効率的に管理し、関心の分離を維持できる。

#### 受け入れ条件

1. リポジトリがクローンされたとき、システムは `experiments/`・`frontend/`・`backend/inference/`・`backend/training/`・`ml/`・`docs/` ディレクトリを含まなければならない
2. 開発者が `experiments/` に移動したとき、システムは番号付きJupyter Notebook（00-04）と `go_onnx_validation/` サブディレクトリを含まなければならない
3. 開発者が `backend/inference/` に移動したとき、システムは `cmd/`・`internal/domain/`・`internal/usecase/`・`internal/interface/`・`internal/infrastructure/`・`di/` サブディレクトリを含まなければならない
4. 開発者が `frontend/` に移動したとき、システムはTypeScript設定を持つNext.jsプロジェクトを含まなければならない
5. 開発者が `ml/` に移動したとき、システムは `envs/`・`models/`・`experiments/` サブディレクトリを含まなければならない
6. 開発者が任意のサービスのREADMEを開いたとき、システムはセットアップ手順・環境変数・クイックスタートコマンドを提供しなければならない

## ガードレール（禁止事項）

### アーキテクチャ制約

1. **ドメイン層の分離**: ドメイン層のコードは外部ライブラリ（database, HTTP, ONNX）をimportしてはならない。Portインターフェースのみを定義する。
2. **依存方向**: 依存関係は必ず domain ← usecase ← interface/infrastructure の方向を守る。逆方向の依存は禁止。
3. **Port-Adapterパターン**: インフラ層は必ずドメイン層のPortを実装する形を取る。ユースケースが具象クラスに直接依存してはならない。

### 技術制約

1. **フロントエンドでのJavaScript禁止**: フロントエンドはTypeScriptのみを使用する。JavaScriptファイル（.js）の作成は禁止。
2. **npm/yarn禁止**: パッケージマネージャーはpnpmのみを使用する。npm/yarnコマンドの使用は禁止。
3. **CPU版PyTorch禁止**: PyTorchインストール時は必ずCUDA対応版を指定する。CPU版のインストールは禁止。
4. **認証情報のハードコード禁止**: データベース接続情報・APIキーをコードにハードコードしてはならない。必ず環境変数から読み込む。

### 実装制約

1. **WebSocketの直接プロキシ禁止**: WebSocket通信はフロントエンドからGoサーバーへ直接接続する。Next.js API Route経由のプロキシは禁止（レイテンシ増加のため）。
2. **Property Testでのモック禁止**: Property-based testではモックを使用せず、実際の機能を検証する。
3. **Notebook検証のスキップ禁止**: 本実装前に必ず対応するNotebookで手法を検証する。Notebook検証なしでの実装着手は禁止。
4. **手動ONNX配置禁止**: ONNXモデルは訓練完了時に自動変換・保存される。手動でのファイル配置は禁止。

### テスト制約

1. **推論レイテンシ計測なし禁止**: 推論レイテンシ（p95 < 50ms）を計測するログ出力は必須。計測なしでの実装完了は禁止。
2. **WebSocketスキーマ検証なし禁止**: WebSocket payloadは必ずスキーマ定義と一致させる。スキーマ検証なしでの実装は禁止。

## 成功条件（Phase 1完了条件）

Phase 1は以下の全条件を満たした時点で完了とする：

| # | 条件 | 計測方法 | 目標値 |
|---|------|---------|--------|
| 1 | 迷路成功率 | MLflowのsuccess_rateメトリクス | ≥ 70% |
| 2 | 推論レイテンシ | Go推論サーバーのJSON構造化ログ（duration_ms） | p95 < 50ms |
| 3 | WebSocket遅延 | クライアント受信時刻 - サーバー送信時刻 | < 200ms |
| 4 | エージェント動作可視化 | 目視確認 | Canvas上でリアルタイム更新 |
| 5 | 再生コントロール | 目視確認 | Play/Stop/Reset/速度調整が正常動作 |
| 6 | WebSocket自動再接続 | 意図的切断テスト | 切断後5秒以内に再接続 |
| 7 | Q値方向矢印表示 | 目視確認 | 各セルに最大Q値方向の矢印表示 |
| 8 | 訪問済みセル表示 | 目視確認 | エージェント通過セルの色分け表示 |
| 9 | クリーンアーキテクチャ検証 | `go list`/`golangci-lint` | ドメイン層から外部依存なし |
| 10 | 全Notebook実行 | 手動実行 | 00-04全てがエラーなく完了 |

## 非機能要件

### パフォーマンス

- 推論API レイテンシ p95: < 50ms
- WebSocket遅延: < 200ms
- Canvas描画フレームレート: ≥ 30fps

### 観測可能性

- 構造化ログ（JSON形式）: timestamp, level, request_id, duration_ms, error
- MLflowメトリクス: episode_reward, episode_length, loss, success_rate
- MongoDB推論ログ: timestamp, model_id, maze_id, steps, success, total_reward

### 保守性

- 依存関係の方向: domain ← usecase ← interface/infrastructure
- 環境変数による設定管理: DATABASE_URL, MONGODB_URI, MLFLOW_TRACKING_URI
- 各サービスのREADME: セットアップ手順・環境変数・クイックスタート

### 移植性

- ローカル開発: Docker Compose（PostgreSQL, MongoDB）
- 本番環境: Supabase（PostgreSQL）, MongoDB Atlas（M0無料枠）
- 環境切り替え: コード変更なし・環境変数のみで切り替え
