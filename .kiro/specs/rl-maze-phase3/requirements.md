# 要件定義書 - Phase 3

## はじめに

RL Maze Phase 3は、Phase 1・Phase 2で構築したシステムに、MLflowダッシュボード統合・モデル管理画面・GPUリソース監視機能を追加し、エンタープライズ水準の運用機能を完成させるフェーズである。本フェーズでは、実験比較・モデルライフサイクル管理・リソース監視をWebUIから一元的に行えるようにする。

Phase 1・Phase 2で既に実装済みの要素：
- Go推論サーバー（APIゲートウェイ機能を含む）
- Python訓練サービス（FastAPI + WebSocket進捗ストリーミング + MLflow統合）
- 推論UI（Next.js）
- トレーニングUI（Next.js）
- OpenAPI定義
- Docker化

Phase 3で新規実装する要素：
- MLflowダッシュボード画面（実験比較・メトリクス可視化）
- モデル管理画面（モデル一覧・切り替え・メタデータ表示）
- GPUリソース監視ダッシュボード（ローカル実機用）

## 用語集

- **システム**: RL Maze Phase 3システム全体
- **MLflowダッシュボード**: MLflowの実験データを可視化するNext.js画面
- **モデル管理画面**: 訓練済みモデルの一覧・切り替え・削除を行うNext.js画面
- **GPUリソース監視**: nvidia-smiの出力をポーリングしてリアルタイム表示する機能
- **実験**: MLflowで管理される1回の訓練実行
- **モデル**: 訓練済みのONNXファイルとそのメタデータ

## 要件

### 要件1

**ユーザーストーリー:** ユーザーとして、MLflowダッシュボードで実験を比較したい。そうすることで訓練の改善点を見つけ、最適なハイパーパラメータを選択できる。

#### 受け入れ条件

1. ユーザーがMLflowダッシュボード画面にアクセスしたとき、システムはMLflowから全実験の一覧を取得しなければならない
2. システムが実験一覧を表示するとき、experiment_id・アルゴリズム・開始日時・成功率・エピソード数を含まなければならない
3. ユーザーが複数の実験を選択したとき、システムは選択された実験のチェックボックスを表示しなければならない
4. ユーザーが「比較」ボタンをクリックしたとき、システムは選択された実験のメトリクスを並べて表示しなければならない
5. 実験比較画面は、エピソード報酬・損失・成功率のグラフを並べて表示しなければならない
6. 実験比較画面は、各実験の最終メトリクス（最終報酬・最終成功率・総エピソード数）を表形式で表示しなければならない
7. ユーザーが実験をクリックしたとき、システムは実験詳細画面に遷移しなければならない
8. 実験詳細画面は、MLflowダッシュボードへのリンクを提供しなければならない

### 要件2

**ユーザーストーリー:** ユーザーとして、モデル管理画面で訓練済みモデルを管理したい。そうすることでモデルのライフサイクルを一元的に管理できる。

#### 受け入れ条件

1. ユーザーがモデル管理画面にアクセスしたとき、システムはPostgreSQLから全モデルの一覧を取得しなければならない
2. システムがモデル一覧を表示するとき、model_id・アルゴリズム・訓練日時・成功率・ONNXファイルパス・アクティブ状態を含まなければならない
3. アクティブなモデルは、一覧で視覚的に区別されなければならない（バッジまたは色分け）
4. ユーザーがモデルの「アクティブ化」ボタンをクリックしたとき、システムはそのモデルをアクティブに設定しなければならない
5. モデルがアクティブ化されたとき、システムは以前のアクティブモデルを非アクティブに変更しなければならない
6. ユーザーがモデルの「詳細」ボタンをクリックしたとき、システムはモデル詳細画面に遷移しなければならない
7. モデル詳細画面は、モデルメタデータ（アルゴリズム・訓練日時・成功率・エピソード数・ONNXファイルパス）を表示しなければならない
8. モデル詳細画面は、「推論UIで試す」ボタンを提供しなければならない
9. ユーザーが「推論UIで試す」ボタンをクリックしたとき、システムはそのモデルをアクティブ化し、推論UI画面に遷移しなければならない
10. ユーザーがモデルの「削除」ボタンをクリックしたとき、システムは確認ダイアログを表示しなければならない
11. ユーザーが削除を確認したとき、システムはPostgreSQLからモデルメタデータを削除しなければならない
12. アクティブなモデルは削除できないようにしなければならない

### 要件3

**ユーザーストーリー:** ユーザーとして、GPUリソース監視ダッシュボードでGPU使用状況を確認したい。そうすることでトレーニング中のリソース使用状況を把握できる。

#### 受け入れ条件

1. ユーザーがGPUリソース監視画面にアクセスしたとき、システムはnvidia-smiの出力をポーリングしなければならない
2. システムがGPU情報を取得したとき、GPU使用率・メモリ使用量・温度を表示しなければならない
3. GPU使用率は、リアルタイムで更新されるグラフで表示されなければならない
4. GPUメモリ使用量は、使用量/総量の形式で表示されなければならない
5. GPU温度は、現在の温度を表示しなければならない
6. システムがGPU情報を取得できないとき、エラーメッセージを表示しなければならない
7. GPU情報の更新間隔は5秒以内でなければならない
8. トレーニング進行中は、GPU使用率が自動的に上昇することを確認できなければならない

### 要件4

**ユーザーストーリー:** 開発者として、MLflowダッシュボード・モデル管理・GPU監視のコンポーネントが再利用可能であってほしい。そうすることで将来の拡張が容易になる。

#### 受け入れ条件

1. 実験一覧コンポーネントは独立したコンポーネントでなければならない
2. 実験比較コンポーネントは独立したコンポーネントでなければならない
3. モデル一覧コンポーネントは独立したコンポーネントでなければならない
4. モデル詳細コンポーネントは独立したコンポーネントでなければならない
5. GPUメトリクスカードコンポーネントは独立したコンポーネントでなければならない
6. 各コンポーネントはTypeScriptで型定義されなければならない
7. 各コンポーネントはZodでバリデーションされなければならない

### 要件5

**ユーザーストーリー:** 開発者として、MLflow・モデル管理・GPU監視のAPI通信が型安全であってほしい。そうすることでバグを早期に発見できる。

#### 受け入れ条件

1. 実験一覧レスポンスはZodスキーマでバリデーションされなければならない
2. 実験詳細レスポンスはZodスキーマでバリデーションされなければならない
3. モデル一覧レスポンスはZodスキーマでバリデーションされなければならない
4. モデル詳細レスポンスはZodスキーマでバリデーションされなければならない
5. GPU情報レスポンスはZodスキーマでバリデーションされなければならない
6. 無効なレスポンスに対して、システムは明確なエラーメッセージを表示しなければならない

### 要件6

**ユーザーストーリー:** ユーザーとして、MLflowダッシュボード・モデル管理・GPU監視のUIが直感的で使いやすいものであってほしい。そうすることでストレスなく運用できる。

#### 受け入れ条件

1. 実験一覧は、ソート機能（日時・成功率）を提供しなければならない
2. 実験一覧は、フィルター機能（アルゴリズム）を提供しなければならない
3. モデル一覧は、ソート機能（日時・成功率）を提供しなければならない
4. モデル一覧は、フィルター機能（アルゴリズム・アクティブ状態）を提供しなければならない
5. 削除確認ダイアログは、削除対象のモデル情報を表示しなければならない
6. ローディング中は、ローディングインジケーターを表示しなければならない
7. エラー発生時は、エラーメッセージとリトライボタンを表示しなければならない

## ガードレール（禁止事項）

### アーキテクチャ制約

1. **Phase 1・Phase 2の設計原則を維持**: Phase 1・Phase 2で確立したクリーンアーキテクチャ・型安全性・バリデーション戦略を維持する。
2. **コンポーネントの独立性**: Phase 3のコンポーネントは、Phase 1・Phase 2のコンポーネントと独立して動作しなければならない。

### 技術制約

1. **フロントエンドでのJavaScript禁止**: フロントエンドはTypeScriptのみを使用する。JavaScriptファイル（.js）の作成は禁止。
2. **npm/yarn禁止**: パッケージマネージャーはpnpmのみを使用する。
3. **認証情報のハードコード禁止**: APIエンドポイントURLをコードにハードコードしてはならない。必ず環境変数から読み込む。

### 実装制約

1. **Phase 1・Phase 2の既存機能を破壊しない**: Phase 3の追加は、Phase 1・Phase 2で実装した機能に影響を与えてはならない。
2. **GPU監視はローカル実機専用**: nvidia-smiを使用するため、ローカル実機でのみ動作する。クラウド移行時はAWS CloudWatch等に切り替える設計にする。

### テスト制約

1. **GPU情報更新間隔の計測**: GPU情報の更新間隔（< 5秒）を計測するログ出力は必須。
2. **バリデーションテスト**: 全てのAPIレスポンスはZodでバリデーションされなければならない。

## 成功条件（Phase 3完了条件）

Phase 3は以下の全条件を満たした時点で完了とする：

| # | 条件 | 計測方法 | 目標値 |
|---|------|---------|--------|
| 1 | 実験一覧表示 | 目視確認 | MLflowから実験一覧が表示される |
| 2 | 実験比較 | 目視確認 | 複数実験のメトリクスを並べて比較できる |
| 3 | モデル一覧表示 | 目視確認 | PostgreSQLからモデル一覧が表示される |
| 4 | モデル切り替え | 目視確認 | モデルをアクティブ化できる |
| 5 | モデル削除 | 目視確認 | 非アクティブモデルを削除できる |
| 6 | GPU監視 | 目視確認 | GPU使用率・メモリ・温度がリアルタイム表示される |
| 7 | GPU情報更新間隔 | サーバーログ | < 5秒 |
| 8 | バリデーション | 自動テスト | 全APIレスポンスがZodでバリデーションされる |
| 9 | エラーハンドリング | 目視確認 | エラー発生時に明確なメッセージが表示される |
| 10 | Phase 1・Phase 2機能の維持 | 自動テスト | Phase 1・Phase 2の全テストが通過する |

## 非機能要件

### パフォーマンス

- GPU情報更新間隔: < 5秒
- UI応答性: ボタンクリックから画面遷移まで < 500ms

### 観測可能性

- GPU情報ログ: timestamp, gpu_id, utilization, memory_used, memory_total, temperature
- エラーログ: timestamp, level, error_message, stack_trace

### 保守性

- コンポーネントの独立性: 各コンポーネントは独立してテスト可能
- 型安全性: 全てのAPIリクエスト・レスポンスはTypeScript + Zodで型定義

### 移植性

- Phase 1・Phase 2との互換性: Phase 1・Phase 2の全機能が引き続き動作する
- 環境変数による設定管理: NEXT_PUBLIC_MLFLOW_URL, NEXT_PUBLIC_GPU_MONITOR_URL
