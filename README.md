# RL Maze

RL Maze is a minimal AI inference platform demo that shows how to take reinforcement learning from experimentation to production.

- Reinforcement Learning (PPO / DQN)
- ONNX model export
- Go-based inference backend
- Real-time visualization (Next.js + WebSocket)
- MLOps-ready architecture

This project focuses on bridging the gap between PoC and production AI systems.

---

This repository bridges the gap between academic experimentation and real-world AI systems.

„Åì„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÅØ„ÄÅ  
Â≠¶Ë°ìÁöÑ„Å™ÂÆüÈ®ì„Å®ÁèæÂÆü„ÅÆAI„Ç∑„Çπ„ÉÜ„É†„ÅÆÈñì„Å´„ÅÇ„Çã„ÇÆ„É£„ÉÉ„Éó„ÇíÂüã„ÇÅ„Çã„Åì„Å®„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

---

RL Maze „ÅØ„ÄÅÂº∑ÂåñÂ≠¶ÁøíÔºàRLÔºâ„Çí‰Ωø„Å£„ÅüÂçò„Å™„Çã„Éá„É¢„Åß„ÅØ„Å™„Åè„ÄÅ  
**„ÄåAI PoC „ÇíÂãï„Åè„Éó„É≠„Éà„Çø„Ç§„Éó„ÅßÁµÇ„Çè„Çâ„Åõ„Åö„ÄÅÊú¨Áï™ÈÅãÁî®„Å´Êé•Á∂ö„Åô„Çã„Åü„ÇÅ„ÅÆÊúÄÂ∞èÊßãÊàê„Äç** „ÇíÁ§∫„ÅôÂÄã‰∫∫R&D„Éù„Éº„Éà„Éï„Ç©„É™„Ç™„Åß„Åô„ÄÇ

ÂÆüÈ®ìÔºàNotebookÔºâ‚Üí Â≠¶Áøí ‚Üí ONNXÂ§âÊèõ ‚Üí GoÊé®Ë´ñ„Çµ„Éº„Éê„Éº ‚Üí „É™„Ç¢„É´„Çø„Ç§„É†ÂèØË¶ñÂåñ„Åæ„Åß„Çí‰∏ÄË≤´„Åó„Å¶ÊßãÊàê„Åó„ÄÅ  
AIÈñãÁô∫„Å´„Åä„Åë„Çã *Á†îÁ©∂„Å®„Éó„É≠„ÉÄ„ÇØ„Éà„ÅÆÊñ≠Áµ∂* „ÇíÂüã„ÇÅ„Çã„Åì„Å®„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

---

## What this project demonstrates

- Experiment-to-production workflow for Reinforcement Learning
- Lightweight inference using Go + ONNX
- Real-time agent visualization via WebSocket
- Production-oriented design (health checks, logging, OpenAPI, Docker)
- Cost-aware AI system architecture (rate limiting, GPU usage, scalability)

---

## „Åì„ÅÆ„Éó„É≠„Ç∏„Çß„ÇØ„Éà„ÅßÁ§∫„Åó„Å¶„ÅÑ„Çã„Åì„Å®

- RLÂÆüÈ®ì„Åã„Çâ„Éó„É≠„ÉÄ„ÇØ„Ç∑„Éß„É≥„Åæ„Åß„ÅÆ‰∏ÄË≤´„Åó„ÅüÈñãÁô∫„Éï„É≠„Éº
- Go + ONNX„Å´„Çà„ÇãËªΩÈáèÊé®Ë´ñÂü∫Áõ§
- WebSocket„Çí‰Ωø„Å£„Åü„É™„Ç¢„É´„Çø„Ç§„É†ÂèØË¶ñÂåñ
- ÈÅãÁî®ÂâçÊèê„ÅÆË®≠Ë®àÔºà„Éò„É´„Çπ„ÉÅ„Çß„ÉÉ„ÇØ„Éª„É≠„Ç∞„ÉªOpenAPI„ÉªDockerÔºâ
- Â∞ÜÊù•„ÅÆSaaSÂåñ„ÇÑGPUÈÅãÁî®„ÇíË¶ãÊçÆ„Åà„Åü„Ç≥„Çπ„ÉàË®≠Ë®à

---

## Roadmap

```mermaid
gantt
    title RL Maze Roadmap
    dateFormat  YYYY-MM-DD
    section Experiments
    00_rl_basic.ipynb              :2026-02-23, 3d
    01_dqn_basic.ipynb             :3d
    02_ppo_basic.ipynb             :3d
    03_maze_env.ipynb              :3d
    04_onnx_export.ipynb           :3d
    go_onnx_validation             :3d
    section Phase 1 - Core
    Maze Environment               :7d
    Go Inference Server            :7d
    NextJS Inference UI            :7d
    section Phase 2 - Enterprise
    API Gateway / Docker           :7d
    Training UI                    :5d
    section Phase 3 - MLOps
    MLflow Dashboard               :5d
    GPU Monitoring Dashboard       :3d
```

---

üìÑ Ë®≠Ë®àÊÄùÊÉ≥„Éª„Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§„Éª„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÅÆË©≥Á¥∞„ÅØ„Åì„Å°„Çâ  
üëâ [docs/architecture.md](docs/architecture.md)

üìì ÂÆüÈ®ì„Éé„Éº„Éà„ÉªNotebook„ÅÆÂÆüË°åÊâãÈ†Ü„ÅØ„Åì„Å°„Çâ  
üëâ [experiments/README.md](experiments/README.md)

---

## Quick Start

> üöß Currently under construction. Each service will be available progressively.

### Python Virtual Environment Setup

This project uses `uv` for Python package management. A virtual environment has been created at `.venv/`.

**Activate the virtual environment:**

- **Windows:**
  ```bash
  .venv\Scripts\activate
  ```

- **Linux/Mac:**
  ```bash
  source .venv/bin/activate
  ```

After activation, your terminal prompt should show `(.venv)` prefix.

### Service-Specific Setup

Please refer to each service README for detailed setup instructions.

- Frontend: `frontend/README.md`
- Inference Server: `backend/inference/README.md`
- Training Service: `backend/training/README.md`

---

## Docker Compose Setup

The project includes a `docker-compose.yml` file for running PostgreSQL and MongoDB locally for development.

### Starting the databases

```bash
docker-compose up -d
```

This will start:
- **PostgreSQL** on port 5432 (used by inference server, training service, and MLflow)
- **MongoDB** on port 27017 (used by inference server for logging)

### Stopping the databases

```bash
docker-compose down
```

### Stopping and removing volumes (‚ö†Ô∏è deletes all data)

```bash
docker-compose down -v
```

### Checking service status

```bash
docker-compose ps
```

### Viewing logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f postgres
docker-compose logs -f mongodb
```

### Connection strings for local development

Once the services are running, use these connection strings in your `.env` files:

- **PostgreSQL:** `postgresql://postgres:postgres@localhost:5432/rl_maze?sslmode=disable`
- **MongoDB:** `mongodb://localhost:27017/rl_maze_logs`

### Data persistence

Data is persisted in Docker volumes:
- `postgres_data`: PostgreSQL database files
- `mongodb_data`: MongoDB database files
- `mongodb_config`: MongoDB configuration files

These volumes persist even after `docker-compose down`, ensuring your data is not lost between restarts.
