{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. å¼·åŒ–å­¦ç¿’ã®åŸºç¤ - ãªãœRLãŒå¿…è¦ã‹\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€CartPoleç’°å¢ƒã‚’ä½¿ã£ã¦ä»¥ä¸‹ã‚’å®Ÿè¨¼ã—ã¾ã™ï¼š\n",
    "\n",
    "1. **ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: å­¦ç¿’ãªã—ã§ãƒ©ãƒ³ãƒ€ãƒ ã«è¡Œå‹•ã‚’é¸æŠ\n",
    "2. **è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è¨“ç·´ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "3. **å­¦ç¿’æ›²ç·š**: è¨“ç·´ä¸­ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å¯è¦–åŒ–\n",
    "\n",
    "ã“ã‚Œã«ã‚ˆã‚Šã€å¼·åŒ–å­¦ç¿’ãŒãªãœå¿…è¦ã‹ã‚’è¦–è¦šçš„ã«ç†è§£ã§ãã¾ã™ã€‚\n",
    "\n",
    "## è¦ä»¶\n",
    "- è¦ä»¶ 1.1: CartPoleç’°å¢ƒã§ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸¦ã¹ã¦è¡¨ç¤º\n",
    "- å­¦ç¿’æ›²ç·šã‚’è¨˜éŒ²ã—ã€ã€ŒãªãœRLãŒå¿…è¦ã‹ã€ã‚’è¦–è¦šçš„ã«ç¤ºã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CartPoleç’°å¢ƒã®ç†è§£\n",
    "\n",
    "CartPole-v1ã¯å¤å…¸çš„ãªåˆ¶å¾¡å•é¡Œã§ã™ï¼š\n",
    "- **ç›®æ¨™**: ã‚«ãƒ¼ãƒˆã‚’å·¦å³ã«å‹•ã‹ã—ã¦ã€ãƒãƒ¼ãƒ«ã‚’ç«‹ã¦ãŸã¾ã¾ä¿ã¤\n",
    "- **è¦³æ¸¬**: ã‚«ãƒ¼ãƒˆä½ç½®ã€ã‚«ãƒ¼ãƒˆé€Ÿåº¦ã€ãƒãƒ¼ãƒ«è§’åº¦ã€ãƒãƒ¼ãƒ«è§’é€Ÿåº¦ï¼ˆ4æ¬¡å…ƒï¼‰\n",
    "- **è¡Œå‹•**: å·¦ã«æŠ¼ã™ï¼ˆ0ï¼‰ã¾ãŸã¯å³ã«æŠ¼ã™ï¼ˆ1ï¼‰\n",
    "- **å ±é…¬**: ãƒãƒ¼ãƒ«ãŒç«‹ã£ã¦ã„ã‚‹é–“ã€æ¯ã‚¹ãƒ†ãƒƒãƒ—+1\n",
    "- **çµ‚äº†æ¡ä»¶**: ãƒãƒ¼ãƒ«ãŒ15åº¦ä»¥ä¸Šå‚¾ãã€ã‚«ãƒ¼ãƒˆãŒç”»é¢å¤–ã«å‡ºã‚‹ã€ã¾ãŸã¯500ã‚¹ãƒ†ãƒƒãƒ—é”æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CartPoleç’°å¢ƒã®ä½œæˆ\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "print(f\"è¦³æ¸¬ç©ºé–“: {env.observation_space}\")\n",
    "print(f\"è¡Œå‹•ç©ºé–“: {env.action_space}\")\n",
    "print(f\"æœ€å¤§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é•·: 500ã‚¹ãƒ†ãƒƒãƒ—\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡\n",
    "\n",
    "ã¾ãšã€å­¦ç¿’ãªã—ã§ãƒ©ãƒ³ãƒ€ãƒ ã«è¡Œå‹•ã‚’é¸æŠã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_agent(env, n_episodes=10):\n",
    "    \"\"\"\n",
    "    ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡\n",
    "    \n",
    "    Args:\n",
    "        env: Gymç’°å¢ƒ\n",
    "        n_episodes: è©•ä¾¡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°\n",
    "    \n",
    "    Returns:\n",
    "        episode_rewards: å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ç´¯ç©å ±é…¬ãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            # ãƒ©ãƒ³ãƒ€ãƒ ã«è¡Œå‹•ã‚’é¸æŠ\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "    \n",
    "    return episode_rewards\n",
    "\n",
    "# ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡\n",
    "env = gym.make('CartPole-v1')\n",
    "random_rewards = evaluate_random_agent(env, n_episodes=10)\n",
    "env.close()\n",
    "\n",
    "print(f\"ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:\")\n",
    "print(f\"  å¹³å‡å ±é…¬: {np.mean(random_rewards):.2f} Â± {np.std(random_rewards):.2f}\")\n",
    "print(f\"  æœ€å°å ±é…¬: {np.min(random_rewards):.2f}\")\n",
    "print(f\"  æœ€å¤§å ±é…¬: {np.max(random_rewards):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´\n",
    "\n",
    "æ¬¡ã«ã€PPOï¼ˆProximal Policy Optimizationï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ã£ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã—ã¾ã™ã€‚\n",
    "è¨“ç·´ä¸­ã®å­¦ç¿’æ›²ç·šã‚’è¨˜éŒ²ã—ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å‘ä¸Šã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ç”¨ç’°å¢ƒã®ä½œæˆ\n",
    "train_env = gym.make('CartPole-v1')\n",
    "\n",
    "# PPOãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ\n",
    "print(\"PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ä¸­...\")\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    verbose=0,\n",
    "    learning_rate=0.001,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    ")\n",
    "\n",
    "# å­¦ç¿’æ›²ç·šã‚’è¨˜éŒ²ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯\n",
    "class LearningCurveCallback:\n",
    "    def __init__(self, eval_env, eval_freq=2000):\n",
    "        self.eval_env = eval_env\n",
    "        self.eval_freq = eval_freq\n",
    "        self.timesteps = []\n",
    "        self.mean_rewards = []\n",
    "        self.current_timestep = 0\n",
    "    \n",
    "    def __call__(self, locals_dict, globals_dict):\n",
    "        self.current_timestep += 1\n",
    "        \n",
    "        if self.current_timestep % self.eval_freq == 0:\n",
    "            # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡\n",
    "            mean_reward, _ = evaluate_policy(\n",
    "                locals_dict['self'],\n",
    "                self.eval_env,\n",
    "                n_eval_episodes=5,\n",
    "                deterministic=True\n",
    "            )\n",
    "            self.timesteps.append(self.current_timestep)\n",
    "            self.mean_rewards.append(mean_reward)\n",
    "            print(f\"  ã‚¹ãƒ†ãƒƒãƒ— {self.current_timestep}: å¹³å‡å ±é…¬ = {mean_reward:.2f}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "# è©•ä¾¡ç”¨ç’°å¢ƒ\n",
    "eval_env = gym.make('CartPole-v1')\n",
    "callback = LearningCurveCallback(eval_env, eval_freq=2000)\n",
    "\n",
    "# è¨“ç·´å®Ÿè¡Œï¼ˆ20,000ã‚¹ãƒ†ãƒƒãƒ—ï¼‰\n",
    "model.learn(total_timesteps=20000, callback=callback, progress_bar=True)\n",
    "\n",
    "print(\"\\nâœ… è¨“ç·´å®Œäº†\")\n",
    "\n",
    "train_env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡\n",
    "eval_env = gym.make('CartPole-v1')\n",
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model,\n",
    "    eval_env,\n",
    "    n_eval_episodes=10,\n",
    "    deterministic=True\n",
    ")\n",
    "eval_env.close()\n",
    "\n",
    "print(f\"è¨“ç·´æ¸ˆã¿PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:\")\n",
    "print(f\"  å¹³å‡å ±é…¬: {mean_reward:.2f} Â± {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å­¦ç¿’æ›²ç·šã®å¯è¦–åŒ–\n",
    "\n",
    "è¨“ç·´ä¸­ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’æ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(callback.timesteps, callback.mean_rewards, marker='o', linewidth=2, markersize=8)\n",
    "plt.axhline(y=np.mean(random_rewards), color='r', linestyle='--', label=f'ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (å¹³å‡: {np.mean(random_rewards):.2f})')\n",
    "plt.axhline(y=500, color='g', linestyle='--', label='æœ€å¤§å ±é…¬ (500)', alpha=0.5)\n",
    "plt.xlabel('è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°', fontsize=12)\n",
    "plt.ylabel('å¹³å‡ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å ±é…¬', fontsize=12)\n",
    "plt.title('PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å­¦ç¿’æ›²ç·š - CartPole-v1', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š å­¦ç¿’æ›²ç·šã®è§£é‡ˆ:\")\n",
    "print(f\"  - ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: å¹³å‡ {np.mean(random_rewards):.2f} å ±é…¬\")\n",
    "print(f\"  - è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: å¹³å‡ {mean_reward:.2f} å ±é…¬\")\n",
    "print(f\"  - æ”¹å–„ç‡: {((mean_reward - np.mean(random_rewards)) / np.mean(random_rewards) * 100):.1f}%\")\n",
    "print(\"\\nğŸ’¡ ã“ã‚ŒãŒå¼·åŒ–å­¦ç¿’ã®åŠ›ã§ã™ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ vs è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¯è¦–åŒ–\n",
    "\n",
    "ä¸¡æ–¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã‚’ä¸¦ã¹ã¦æ¯”è¼ƒã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, agent_type='random', model=None, max_steps=500):\n",
    "    \"\"\"\n",
    "    1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¨˜éŒ²\n",
    "    \n",
    "    Args:\n",
    "        env: Gymç’°å¢ƒ\n",
    "        agent_type: 'random' ã¾ãŸã¯ 'trained'\n",
    "        model: è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆagent_type='trained'ã®å ´åˆï¼‰\n",
    "        max_steps: æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°\n",
    "    \n",
    "    Returns:\n",
    "        frames: ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ\n",
    "        total_reward: ç´¯ç©å ±é…¬\n",
    "        steps: ã‚¹ãƒ†ãƒƒãƒ—æ•°\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    while not done and steps < max_steps:\n",
    "        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¨˜éŒ²\n",
    "        frames.append(env.render())\n",
    "        \n",
    "        # è¡Œå‹•ã‚’é¸æŠ\n",
    "        if agent_type == 'random':\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "    \n",
    "    return frames, total_reward, steps\n",
    "\n",
    "# ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰\n",
    "print(\"ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’è¨˜éŒ²ä¸­...\")\n",
    "env_random = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "random_frames, random_reward, random_steps = run_episode(env_random, agent_type='random')\n",
    "env_random.close()\n",
    "\n",
    "# è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰\n",
    "print(\"è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’è¨˜éŒ²ä¸­...\")\n",
    "env_trained = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "trained_frames, trained_reward, trained_steps = run_episode(env_trained, agent_type='trained', model=model)\n",
    "env_trained.close()\n",
    "\n",
    "print(f\"\\nãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {random_steps}ã‚¹ãƒ†ãƒƒãƒ—, å ±é…¬={random_reward:.0f}\")\n",
    "print(f\"è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {trained_steps}ã‚¹ãƒ†ãƒƒãƒ—, å ±é…¬={trained_reward:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_side_by_side_animation(frames1, frames2, title1, title2, reward1, reward2):\n",
    "    \"\"\"\n",
    "    2ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸¦ã¹ã¦è¡¨ç¤º\n",
    "    \n",
    "    Args:\n",
    "        frames1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        frames2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2ã®ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "        title1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®ã‚¿ã‚¤ãƒˆãƒ«\n",
    "        title2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2ã®ã‚¿ã‚¤ãƒˆãƒ«\n",
    "        reward1: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®å ±é…¬\n",
    "        reward2: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2ã®å ±é…¬\n",
    "    \n",
    "    Returns:\n",
    "        HTML animation\n",
    "    \"\"\"\n",
    "    # çŸ­ã„æ–¹ã«åˆã‚ã›ã‚‹\n",
    "    min_frames = min(len(frames1), len(frames2))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # åˆæœŸãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    im1 = ax1.imshow(frames1[0])\n",
    "    ax1.set_title(f'{title1}\\nå ±é…¬: {reward1:.0f}', fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    im2 = ax2.imshow(frames2[0])\n",
    "    ax2.set_title(f'{title2}\\nå ±é…¬: {reward2:.0f}', fontsize=12, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    def update(frame):\n",
    "        if frame < len(frames1):\n",
    "            im1.set_array(frames1[frame])\n",
    "        if frame < len(frames2):\n",
    "            im2.set_array(frames2[frame])\n",
    "        return [im1, im2]\n",
    "    \n",
    "    anim = animation.FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        frames=min_frames,\n",
    "        interval=50,\n",
    "        blit=True\n",
    "    )\n",
    "    \n",
    "    plt.close()\n",
    "    return HTML(anim.to_jshtml())\n",
    "\n",
    "# ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n",
    "print(\"ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆä¸­...\")\n",
    "anim = create_side_by_side_animation(\n",
    "    random_frames,\n",
    "    trained_frames,\n",
    "    'ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ',\n",
    "    'è¨“ç·´æ¸ˆã¿PPOã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ',\n",
    "    random_reward,\n",
    "    trained_reward\n",
    ")\n",
    "\n",
    "print(\"âœ… ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†\")\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ã¾ã¨ã‚\n",
    "\n",
    "### ãªãœå¼·åŒ–å­¦ç¿’ãŒå¿…è¦ã‹ï¼Ÿ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ä»¥ä¸‹ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸï¼š\n",
    "\n",
    "1. **ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é™ç•Œ**\n",
    "   - ãƒ©ãƒ³ãƒ€ãƒ ã«è¡Œå‹•ã‚’é¸æŠã™ã‚‹ã ã‘ã§ã¯ã€å¹³å‡20-30ã‚¹ãƒ†ãƒƒãƒ—ç¨‹åº¦ã—ã‹æŒç¶šã§ããªã„\n",
    "   - ç’°å¢ƒã®å‹•åŠ›å­¦ã‚’ç†è§£ã—ã¦ã„ãªã„ãŸã‚ã€ä¸€è²«ã—ãŸæˆ¦ç•¥ãŒãªã„\n",
    "\n",
    "2. **å­¦ç¿’ã«ã‚ˆã‚‹æ”¹å–„**\n",
    "   - PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è¨“ç·´ã™ã‚‹ã“ã¨ã§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒåŠ‡çš„ã«å‘ä¸Š\n",
    "   - å­¦ç¿’æ›²ç·šã‹ã‚‰ã€è¨“ç·´ãŒé€²ã‚€ã«ã¤ã‚Œã¦å ±é…¬ãŒå¢—åŠ ã™ã‚‹ã“ã¨ãŒç¢ºèªã§ãã‚‹\n",
    "   - æœ€çµ‚çš„ã«ã¯æœ€å¤§å ±é…¬ï¼ˆ500ã‚¹ãƒ†ãƒƒãƒ—ï¼‰ã«è¿‘ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆ\n",
    "\n",
    "3. **è¦–è¦šçš„ãªé•ã„**\n",
    "   - ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ãƒãƒ¼ãƒ«ãŒã™ãã«å€’ã‚Œã‚‹\n",
    "   - è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ãƒãƒ¼ãƒ«ã‚’å®‰å®šã—ã¦ç«‹ã¦ç¶šã‘ã‚‹\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "- **01_dqn_basic.ipynb**: DQNã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè£…ã¨è©•ä¾¡\n",
    "- **02_ppo_basic.ipynb**: PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è©³ç´°ãªå®Ÿè£…\n",
    "- **03_maze_env.ipynb**: ã‚«ã‚¹ã‚¿ãƒ è¿·è·¯ç’°å¢ƒã®å®Ÿè£…\n",
    "- **04_onnx_export.ipynb**: ãƒ¢ãƒ‡ãƒ«ã®ONNXå½¢å¼ã¸ã®å¤‰æ›\n",
    "\n",
    "### è¦ä»¶ã®æ¤œè¨¼\n",
    "\n",
    "âœ… **è¦ä»¶ 1.1**: CartPoleç’°å¢ƒã§ãƒ©ãƒ³ãƒ€ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨è¨“ç·´æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸¦ã¹ã¦è¡¨ç¤º  \n",
    "âœ… å­¦ç¿’æ›²ç·šã‚’è¨˜éŒ²ã—ã€ã€ŒãªãœRLãŒå¿…è¦ã‹ã€ã‚’è¦–è¦šçš„ã«ç¤ºã™"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
