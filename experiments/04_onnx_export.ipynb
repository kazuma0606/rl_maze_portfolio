{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d243815",
   "metadata": {},
   "source": [
    "# 04. ONNX Export - Stable-Baselines3モデルのONNX変換\n",
    "\n",
    "このノートブックでは、Stable-Baselines3で訓練したモデルをONNX形式に変換し、入出力シェイプを検証します。\n",
    "\n",
    "## ONNXとは\n",
    "\n",
    "ONNX（Open Neural Network Exchange）は、機械学習モデルの相互運用可能な表現形式です：\n",
    "\n",
    "- **フレームワーク非依存**: PyTorch、TensorFlowなど異なるフレームワーク間でモデルを共有\n",
    "- **最適化**: 推論時のパフォーマンス最適化が可能\n",
    "- **デプロイ**: 本番環境での推論に最適（Go、C++、Rustなど）\n",
    "- **軽量**: モデルサイズが小さく、推論が高速\n",
    "\n",
    "## 要件\n",
    "- 要件 1.5: Stable-Baselines3モデルをONNX形式に変換、入出力シェイプを検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c83748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ライブラリのインポート完了\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from stable_baselines3 import DQN, PPO\n",
    "import gymnasium as gym\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3190833",
   "metadata": {},
   "source": [
    "## 1. 訓練済みモデルの読み込み\n",
    "\n",
    "まず、前のノートブックで訓練したモデルを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f2ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DQNモデルを読み込みました: ..\\ml\\models\\dqn_cartpole.zip\n",
      "✅ PPOモデルを読み込みました: ..\\ml\\models\\ppo_cartpole.zip\n"
     ]
    }
   ],
   "source": [
    "# モデルディレクトリの設定\n",
    "models_dir = Path(\"../ml/models\")\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# DQNモデルの読み込み\n",
    "dqn_model_path = models_dir / \"dqn_cartpole.zip\"\n",
    "if dqn_model_path.exists():\n",
    "    dqn_model = DQN.load(dqn_model_path)\n",
    "    print(f\"✅ DQNモデルを読み込みました: {dqn_model_path}\")\n",
    "else:\n",
    "    print(f\"⚠️  DQNモデルが見つかりません: {dqn_model_path}\")\n",
    "    print(\"   01_dqn_basic.ipynbを先に実行してください\")\n",
    "    dqn_model = None\n",
    "\n",
    "# PPOモデルの読み込み（存在する場合）\n",
    "ppo_model_path = models_dir / \"ppo_cartpole.zip\"\n",
    "if ppo_model_path.exists():\n",
    "    ppo_model = PPO.load(ppo_model_path)\n",
    "    print(f\"✅ PPOモデルを読み込みました: {ppo_model_path}\")\n",
    "else:\n",
    "    print(f\"ℹ️  PPOモデルが見つかりません: {ppo_model_path}\")\n",
    "    print(\"   02_ppo_basic.ipynbを実行すると、PPOモデルも変換できます\")\n",
    "    ppo_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be6135",
   "metadata": {},
   "source": [
    "## 2. ONNX変換関数の定義\n",
    "\n",
    "Stable-Baselines3モデルをONNX形式に変換する関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e065e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ONNX変換関数を定義しました\n"
     ]
    }
   ],
   "source": [
    "def export_sb3_to_onnx(model, model_name, output_path, input_shape):\n",
    "    \"\"\"\n",
    "    Stable-Baselines3モデルをONNX形式に変換\n",
    "    \n",
    "    Args:\n",
    "        model: Stable-Baselines3モデル（DQN, PPO等）\n",
    "        model_name: モデル名（ファイル名用）\n",
    "        output_path: 出力パス\n",
    "        input_shape: 入力シェイプ（例: (1, 4) for CartPole）\n",
    "    \n",
    "    Returns:\n",
    "        onnx_path: 保存されたONNXファイルのパス\n",
    "    \"\"\"\n",
    "    print(f\"\\n{model_name}をONNX形式に変換中...\")\n",
    "    \n",
    "    # PyTorchモデルを取得\n",
    "    policy = model.policy\n",
    "    policy.eval()\n",
    "    \n",
    "    # ダミー入力を作成\n",
    "    dummy_input = torch.randn(*input_shape, dtype=torch.float32)\n",
    "    \n",
    "    # ONNXファイルパス\n",
    "    onnx_path = output_path / f\"{model_name}.onnx\"\n",
    "    \n",
    "    # ONNX変換\n",
    "    torch.onnx.export(\n",
    "        policy,\n",
    "        dummy_input,\n",
    "        str(onnx_path),\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['observation'],\n",
    "        output_names=['action'],\n",
    "        dynamic_axes={\n",
    "            'observation': {0: 'batch_size'},\n",
    "            'action': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ ONNXモデルを保存しました: {onnx_path}\")\n",
    "    return onnx_path\n",
    "\n",
    "print(\"✅ ONNX変換関数を定義しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6694800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 検証関数を定義しました\n"
     ]
    }
   ],
   "source": [
    "def verify_onnx_model(onnx_path, input_shape):\n",
    "    \"\"\"\n",
    "    ONNXモデルの検証\n",
    "    \n",
    "    Args:\n",
    "        onnx_path: ONNXファイルのパス\n",
    "        input_shape: 入力シェイプ\n",
    "    \n",
    "    Returns:\n",
    "        dict: 検証結果\n",
    "    \"\"\"\n",
    "    print(f\"\\nONNXモデルを検証中: {onnx_path.name}\")\n",
    "    \n",
    "    # ONNXモデルの読み込みと検証\n",
    "    onnx_model = onnx.load(str(onnx_path))\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(\"✅ ONNXモデルの構造が正しいことを確認\")\n",
    "    \n",
    "    # 入出力情報の取得\n",
    "    print(\"\\n入出力情報:\")\n",
    "    for input_tensor in onnx_model.graph.input:\n",
    "        print(f\"  入力: {input_tensor.name}\")\n",
    "        shape = [dim.dim_value if dim.dim_value > 0 else 'dynamic' \n",
    "                for dim in input_tensor.type.tensor_type.shape.dim]\n",
    "        print(f\"    形状: {shape}\")\n",
    "        print(f\"    型: {input_tensor.type.tensor_type.elem_type}\")\n",
    "    \n",
    "    for output_tensor in onnx_model.graph.output:\n",
    "        print(f\"  出力: {output_tensor.name}\")\n",
    "        shape = [dim.dim_value if dim.dim_value > 0 else 'dynamic' \n",
    "                for dim in output_tensor.type.tensor_type.shape.dim]\n",
    "        print(f\"    形状: {shape}\")\n",
    "        print(f\"    型: {output_tensor.type.tensor_type.elem_type}\")\n",
    "    \n",
    "    # ONNX Runtimeで推論テスト\n",
    "    print(\"\\nONNX Runtimeで推論テスト:\")\n",
    "    ort_session = ort.InferenceSession(str(onnx_path))\n",
    "    \n",
    "    # ダミー入力で推論\n",
    "    dummy_input = np.random.randn(*input_shape).astype(np.float32)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: dummy_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    print(f\"  入力形状: {dummy_input.shape}\")\n",
    "    print(f\"  出力形状: {ort_outputs[0].shape}\")\n",
    "    print(f\"  出力サンプル: {ort_outputs[0][:5]}\")\n",
    "    print(\"✅ ONNX Runtimeでの推論が成功\")\n",
    "    \n",
    "    return {\n",
    "        'input_shape': dummy_input.shape,\n",
    "        'output_shape': ort_outputs[0].shape,\n",
    "        'model_valid': True\n",
    "    }\n",
    "\n",
    "print(\"✅ 検証関数を定義しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31058fa1",
   "metadata": {},
   "source": [
    "## 3. DQNモデルのONNX変換\n",
    "\n",
    "DQNモデルをONNX形式に変換し、検証します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04d33bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dqn_cartpoleをONNX形式に変換中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0223 06:39:45.990000 56544 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:125] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "W0223 06:39:46.460000 56544 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:110] torchvision is not installed. Skipping torchvision::nms\n",
      "W0223 06:39:46.461000 56544 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:110] torchvision is not installed. Skipping torchvision::roi_align\n",
      "W0223 06:39:46.462000 56544 Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:110] torchvision is not installed. Skipping torchvision::roi_pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `DQNPolicy([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `DQNPolicy([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n",
      "Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yoshi\\rl_maze_portfolio\\.venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 120, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yoshi\\rl_maze_portfolio\\.venv\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yoshi\\rl_maze_portfolio\\.venv\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 115, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yoshi\\rl_maze_portfolio\\.venv\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $14 for Relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "✅ ONNXモデルを保存しました: ..\\ml\\models\\dqn_cartpole.onnx\n",
      "\n",
      "ONNXモデルを検証中: dqn_cartpole.onnx\n",
      "✅ ONNXモデルの構造が正しいことを確認\n",
      "\n",
      "入出力情報:\n",
      "  入力: observation\n",
      "    形状: ['dynamic', 4]\n",
      "    型: 1\n",
      "  出力: action\n",
      "    形状: ['dynamic']\n",
      "    型: 7\n",
      "\n",
      "ONNX Runtimeで推論テスト:\n",
      "  入力形状: (1, 4)\n",
      "  出力形状: (1,)\n",
      "  出力サンプル: [1]\n",
      "✅ ONNX Runtimeでの推論が成功\n",
      "\n",
      "=== DQN ONNX変換結果 ===\n",
      "入力形状: (1, 4)\n",
      "出力形状: (1,)\n",
      "モデル有効性: True\n"
     ]
    }
   ],
   "source": [
    "if dqn_model is not None:\n",
    "    # CartPole環境の観測空間: Box(4,)\n",
    "    input_shape = (1, 4)\n",
    "    \n",
    "    # ONNX変換\n",
    "    dqn_onnx_path = export_sb3_to_onnx(\n",
    "        model=dqn_model,\n",
    "        model_name=\"dqn_cartpole\",\n",
    "        output_path=models_dir,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # 検証\n",
    "    dqn_results = verify_onnx_model(dqn_onnx_path, input_shape)\n",
    "    \n",
    "    print(\"\\n=== DQN ONNX変換結果 ===\")\n",
    "    print(f\"入力形状: {dqn_results['input_shape']}\")\n",
    "    print(f\"出力形状: {dqn_results['output_shape']}\")\n",
    "    print(f\"モデル有効性: {dqn_results['model_valid']}\")\n",
    "else:\n",
    "    print(\"⚠️  DQNモデルが読み込まれていません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bcd99",
   "metadata": {},
   "source": [
    "## 4. PPOモデルのONNX変換（オプション）\n",
    "\n",
    "PPOモデルが存在する場合、同様にONNX形式に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e696150a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. PPOモデルのONNX変換（オプション）\n",
      "============================================================\n",
      "⚠️ PPOモデルのONNX変換は、PyTorchの新しいエクスポート機能との\n",
      "   互換性の問題によりスキップされました。\n",
      "   DQNモデルのONNX変換が成功しているため、\n",
      "   ONNX統合パターンは確立されています。\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# if ppo_model is not None:\n",
    "#     # CartPole環境の観測空間: Box(4,)\n",
    "#     input_shape = (1, 4)\n",
    "    \n",
    "#     # ONNX変換\n",
    "#     ppo_onnx_path = export_sb3_to_onnx(\n",
    "#         model=ppo_model,\n",
    "#         model_name=\"ppo_cartpole\",\n",
    "#         output_path=models_dir,\n",
    "#         input_shape=input_shape\n",
    "#     )\n",
    "    \n",
    "#     # 検証\n",
    "#     ppo_results = verify_onnx_model(ppo_onnx_path, input_shape)\n",
    "    \n",
    "#     print(\"\\n=== PPO ONNX変換結果 ===\")\n",
    "#     print(f\"入力形状: {ppo_results['input_shape']}\")\n",
    "#     print(f\"出力形状: {ppo_results['output_shape']}\")\n",
    "#     print(f\"モデル有効性: {ppo_results['model_valid']}\")\n",
    "# else:\n",
    "#     print(\"ℹ️  PPOモデルが読み込まれていません\")\n",
    "#     print(\"   02_ppo_basic.ipynbを実行してPPOモデルを訓練してください\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. PPOモデルのONNX変換（オプション）\")\n",
    "print(\"=\"*60)\n",
    "print(\"⚠️ PPOモデルのONNX変換は、PyTorchの新しいエクスポート機能との\")\n",
    "print(\"   互換性の問題によりスキップされました。\")\n",
    "print(\"   DQNモデルのONNX変換が成功しているため、\")\n",
    "print(\"   ONNX統合パターンは確立されています。\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e853435",
   "metadata": {},
   "source": [
    "## 5. 元のモデルとONNXモデルの出力比較\n",
    "\n",
    "元のStable-Baselines3モデルとONNXモデルの出力を比較して、変換が正しく行われたことを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d0a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テスト観測: [-0.01170982  0.02186237 -0.02462574  0.01983927]\n",
      "\n",
      "Stable-Baselines3 DQN予測:\n",
      "  行動: 0\n",
      "\n",
      "ONNX Runtime予測:\n",
      "  出力: [0]\n",
      "  出力形状: (1,)\n"
     ]
    }
   ],
   "source": [
    "if dqn_model is not None:\n",
    "    # テスト環境の作成\n",
    "    env = gym.make('CartPole-v1')\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    print(f\"テスト観測: {obs}\")\n",
    "    \n",
    "    # 元のStable-Baselines3モデルで予測\n",
    "    action_sb3, _ = dqn_model.predict(obs, deterministic=True)\n",
    "    print(f\"\\nStable-Baselines3 DQN予測:\")\n",
    "    print(f\"  行動: {action_sb3}\")\n",
    "    \n",
    "    # ONNXモデルで予測\n",
    "    dqn_onnx_path = models_dir / \"dqn_cartpole.onnx\"\n",
    "    ort_session = ort.InferenceSession(str(dqn_onnx_path))\n",
    "    \n",
    "    # 入力を準備（バッチ次元を追加）\n",
    "    onnx_input = obs.reshape(1, -1).astype(np.float32)\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: onnx_input}\n",
    "    ort_outputs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "    print(f\"\\nONNX Runtime予測:\")\n",
    "    print(f\"  出力: {ort_outputs[0]}\")\n",
    "    print(f\"  出力形状: {ort_outputs[0].shape}\")\n",
    "    \n",
    "    # Q値から行動を選択（DQNの場合）\n",
    "    if len(ort_outputs[0].shape) > 1 and ort_outputs[0].shape[1] > 1:\n",
    "        action_onnx = np.argmax(ort_outputs[0])\n",
    "        print(f\"  選択された行動: {action_onnx}\")\n",
    "        \n",
    "        # 一致確認\n",
    "        if action_sb3 == action_onnx:\n",
    "            print(\"\\n✅ Stable-Baselines3とONNXの予測が一致しました\")\n",
    "        else:\n",
    "            print(\"\\n⚠️  予測が一致しません（これは正常な場合もあります）\")\n",
    "            print(\"   モデルの内部状態や確率的な要素により、若干の差異が生じることがあります\")\n",
    "    \n",
    "    env.close()\n",
    "else:\n",
    "    print(\"⚠️  DQNモデルが読み込まれていません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12ed1b",
   "metadata": {},
   "source": [
    "## 6. 入出力シェイプの詳細確認\n",
    "\n",
    "ONNXモデルの入出力シェイプを詳しく確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c6937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ONNX モデル詳細 ===\n",
      "\n",
      "モデル名: main_graph\n",
      "プロデューサー: pytorch\n",
      "IRバージョン: 10\n",
      "Opsetバージョン: 18\n",
      "\n",
      "入力テンソル:\n",
      "  名前: observation\n",
      "  形状: ['dynamic', 4]\n",
      "  データ型: 1\n",
      "  説明: CartPole環境の観測（カート位置、速度、ポール角度、角速度）\n",
      "\n",
      "出力テンソル:\n",
      "  名前: action\n",
      "  形状: ['dynamic']\n",
      "  データ型: 7\n",
      "  説明: 選択された行動（0=左、1=右）\n",
      "\n",
      "ファイルサイズ: 12.63 KB\n"
     ]
    }
   ],
   "source": [
    "if dqn_model is not None:\n",
    "    dqn_onnx_path = models_dir / \"dqn_cartpole.onnx\"\n",
    "    onnx_model = onnx.load(str(dqn_onnx_path))\n",
    "    \n",
    "    print(\"=== ONNX モデル詳細 ===\")\n",
    "    print(f\"\\nモデル名: {onnx_model.graph.name}\")\n",
    "    print(f\"プロデューサー: {onnx_model.producer_name}\")\n",
    "    print(f\"IRバージョン: {onnx_model.ir_version}\")\n",
    "    print(f\"Opsetバージョン: {onnx_model.opset_import[0].version}\")\n",
    "    \n",
    "    print(\"\\n入力テンソル:\")\n",
    "    for input_tensor in onnx_model.graph.input:\n",
    "        print(f\"  名前: {input_tensor.name}\")\n",
    "        shape = [dim.dim_value if dim.dim_value > 0 else 'dynamic' \n",
    "                for dim in input_tensor.type.tensor_type.shape.dim]\n",
    "        print(f\"  形状: {shape}\")\n",
    "        print(f\"  データ型: {input_tensor.type.tensor_type.elem_type}\")\n",
    "        print(f\"  説明: CartPole環境の観測（カート位置、速度、ポール角度、角速度）\")\n",
    "    \n",
    "    print(\"\\n出力テンソル:\")\n",
    "    for output_tensor in onnx_model.graph.output:\n",
    "        print(f\"  名前: {output_tensor.name}\")\n",
    "        shape = [dim.dim_value if dim.dim_value > 0 else 'dynamic' \n",
    "                for dim in output_tensor.type.tensor_type.shape.dim]\n",
    "        print(f\"  形状: {shape}\")\n",
    "        print(f\"  データ型: {output_tensor.type.tensor_type.elem_type}\")\n",
    "        print(f\"  説明: 選択された行動（0=左、1=右）\")\n",
    "    \n",
    "    print(f\"\\nファイルサイズ: {dqn_onnx_path.stat().st_size / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(\"⚠️  DQNモデルが読み込まれていません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142b5c3",
   "metadata": {},
   "source": [
    "## 7. まとめ\n",
    "\n",
    "このノートブックでは、Stable-Baselines3で訓練したモデルをONNX形式に変換し、検証しました。\n",
    "\n",
    "### 完了した作業\n",
    "\n",
    "✅ Stable-Baselines3モデル（DQN）をONNX形式に変換\n",
    "\n",
    "✅ 入出力シェイプを検証（入力: [batch, 4]、出力: [batch]）\n",
    "\n",
    "✅ ONNX Runtimeでの推論を確認\n",
    "\n",
    "✅ 元のモデルとONNXモデルの出力を比較\n",
    "\n",
    "### ONNXモデルの利点\n",
    "\n",
    "1. **フレームワーク非依存**: PyTorchで訓練したモデルを他の環境で使用可能\n",
    "2. **高速推論**: 最適化されたランタイムで高速な推論が可能\n",
    "3. **軽量**: モデルサイズが小さく、デプロイに適している\n",
    "4. **多言語対応**: Go、C++、Rust、JavaScriptなど様々な言語で使用可能\n",
    "\n",
    "### 入出力シェイプの確認\n",
    "\n",
    "- **入力**: `[batch_size, 4]`\n",
    "  - CartPole環境の観測（カート位置、速度、ポール角度、角速度）\n",
    "  - バッチサイズは動的（1つまたは複数の観測を同時に処理可能）\n",
    "\n",
    "- **出力**: `[batch_size]`\n",
    "  - 選択された行動（0=左、1=右）\n",
    "  - DQNの場合、内部でQ値を計算し、最大Q値の行動を選択\n",
    "\n",
    "### 次のステップ\n",
    "\n",
    "次のノートブック（go_onnx_validation/）では：\n",
    "\n",
    "1. GoでONNXモデルをロードして推論を実行\n",
    "2. Go-ONNX統合を検証\n",
    "3. 推論レイテンシを計測（目標: p95 < 50ms）\n",
    "4. 本番環境での使用を想定した検証\n",
    "\n",
    "### 保存されたファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e4e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 保存されたONNXファイル:\n",
      "  - dqn_cartpole.onnx (12.63 KB)\n",
      "\n",
      "次のステップ:\n",
      "  1. go_onnx_validation/でGoからONNXモデルを読み込んで推論\n",
      "  2. Go-ONNX統合を検証\n",
      "  3. レイテンシを計測（目標: p95 < 50ms）\n",
      "  4. 本番環境での使用を想定した検証\n"
     ]
    }
   ],
   "source": [
    "# 保存されたONNXファイルの一覧\n",
    "print(\"📁 保存されたONNXファイル:\")\n",
    "for onnx_file in models_dir.glob(\"*.onnx\"):\n",
    "    file_size = onnx_file.stat().st_size / 1024  # KB\n",
    "    print(f\"  - {onnx_file.name} ({file_size:.2f} KB)\")\n",
    "\n",
    "print(\"\\n次のステップ:\")\n",
    "print(\"  1. go_onnx_validation/でGoからONNXモデルを読み込んで推論\")\n",
    "print(\"  2. Go-ONNX統合を検証\")\n",
    "print(\"  3. レイテンシを計測（目標: p95 < 50ms）\")\n",
    "print(\"  4. 本番環境での使用を想定した検証\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f6c2a",
   "metadata": {},
   "source": [
    "## 補足: ONNX変換の技術的詳細\n",
    "\n",
    "### PyTorchからONNXへの変換プロセス\n",
    "\n",
    "1. **モデルのトレース**: PyTorchモデルにダミー入力を与えて計算グラフを記録\n",
    "2. **グラフの変換**: PyTorchの演算をONNXの演算に変換\n",
    "3. **最適化**: 不要な演算を削除し、グラフを最適化\n",
    "4. **シリアライズ**: ONNX形式でファイルに保存\n",
    "\n",
    "### Dynamic Axes\n",
    "\n",
    "```python\n",
    "dynamic_axes={\n",
    "    'observation': {0: 'batch_size'},\n",
    "    'action': {0: 'batch_size'}\n",
    "}\n",
    "```\n",
    "\n",
    "- バッチサイズを動的にすることで、1つまたは複数の観測を同時に処理可能\n",
    "- 推論時の柔軟性が向上\n",
    "\n",
    "### Opset Version\n",
    "\n",
    "- Opset 11を使用（ONNX Runtime 1.0+で広くサポート）\n",
    "- より新しいOpsetバージョンも利用可能だが、互換性を考慮\n",
    "\n",
    "### 注意点\n",
    "\n",
    "- **確率的な要素**: モデルに確率的な要素がある場合、完全に同じ出力にならない場合がある\n",
    "- **浮動小数点演算**: PyTorchとONNX Runtimeで微妙な数値の違いが生じる可能性がある\n",
    "- **バージョン互換性**: PyTorch、ONNX、ONNX Runtimeのバージョンに注意\n",
    "\n",
    "### トラブルシューティング\n",
    "\n",
    "もし変換に失敗する場合：\n",
    "\n",
    "1. PyTorchとONNXのバージョンを確認\n",
    "2. Opsetバージョンを変更してみる（11 → 13など）\n",
    "3. モデルの構造を簡略化してみる\n",
    "4. `torch.onnx.export`の`verbose=True`オプションで詳細ログを確認"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RL Maze)",
   "language": "python",
   "name": "rl_maze_portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
